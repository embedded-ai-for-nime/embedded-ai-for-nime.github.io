---
layout: default
---

<div class="header-container jumbotron">
    <div class="container">
        <h2 style="color:white";>Embedded AI for NIME: Challenges and Opportunities</h2>
        <h3 style="color:white";><i>Workshop at <a href="https://nime2022.org/">NIME 2022</a></i></h3>
        <h5 style="color:white";>Organisers: Teresa Pelinski, Victor Shepardson, Steve Symons, Franco S. Caspe, Adan L. Benito Temprano, Jack Armitage, Chris Kiefer, Rebecca Fiebrink, Thor Magnusson, and Andrew McPherson </h5>
        <h5 style="color:white";><b><a href="http://www.emutelab.org/">Emute Lab</a> - <a href="https://iil.is/">Intelligent Instruments Lab</a> - <a href="http://instrumentslab.org/">Augmented Instruments Lab</a></b></h5>
    </div>
</div>

<div class="container">
    <h3 class="header-light regular-pad">Thank you!</h2>
      <p>
      We would like to thank the NIME 2022 organizers for the opportunity of hosting this Workshop, and the presenters and attendees for sharing their work and for many interesting discussions.
      We hope this first approach into embedded AI for NIME has sparkled new ideas and shed some light on the challenges and opportunities brought by these technologies to the practices of researchers, musicians and makers.
      </p>
      <p>
      <b>More info and shared material:</b>
      <ul>
  
      <li>The accepted extended abstracts can be found in the <b><a href="/accepted_submissions">Accepted Submissions</a></b> section.</li>
      
      <li>For insight on the discusisons that took place please check out the sessions' <b><a href="https://padlet.com/abenitotemprano/ap10ewnxjwxvg9lv">Padlet</a></b>.</li>
      
      <li>Finally, we have recorded and uploaded the Workshop's sessions for anyone to check out.</li>
        
      <li>We hope to continue exploring this field, and fostering the community with a future, fully open event. <b><a href="https://discord.gg/fY9GYMebtJ">Stay Tuned !</a></b></li>
      </ul>      
      </p>
      <p>
      <h5><i>Workshop Session 1</i></h5>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/H99MRsQ6U3Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </p>
      <p>
      <h5><i>Workshop Session 2</i></h5>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/182iFrClzEA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
      </p>
      
      
</div>

<div class="container">
    <h3 class="header-light regular-pad">Welcome</h2>
      <p>
      With this Workshop we aim to bring together researchers with the common interest of working with and developing embedded AI for 
      <b>New Interfaces for Musical Expression (NIME)</b>, and to jointly identify the challenges, trends, and technologies in use.
      Furthermore, we expect it to serve as the starting point for an embedded AI NIME community and as future reference to help newcomers get started with embedded AI.
      </p>
</div>

<div class="container">
<h3 class="header-light regular-pad">Schedule</h2>

<b>The Workshop took place on Tuesday, 28th June.</b><br>Times are in UTC+1 (London)

<h4 class="header-light regular-pad">Session 1 (12:00 - 15:00)</h4>

<style>
#customers {
  font-family: Arial, Helvetica, sans-serif;
  border-collapse: collapse;
  width: 100%;
}

#customers td, #customers th {
  border: 1px solid #ddd;
  padding: 8px;
}
}

#customers tr:nth-child(even){background-color: #f2f2f2;}

#customers tr:hover {background-color: #ddd;}

#customers {
  table-layout: fixed ;
  width: 100% ;
}

#customers th {
  padding-top: 12px;
  padding-bottom: 12px;
  text-align: left;
  background-color: #000000;
  color: white;
}
</style>
<table id="customers">
<thead>
  <tr>
    <th width="18%",class="tg-1wig">Start</th>
    <th class="tg-1wig">Activity</th>
    <th width="28%",class="tg-1wig">Speakers</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-cly1">12:00</td>
    <td class="tg-cly1">Welcome and introduction</td>
    <td class="tg-1wig"></td>
  </tr>
  <tr>
    <td class="tg-cly1">12:05</td>
    <td class="tg-cly1">Considering Ethics, Culture and Invention in Embedded AI Research for NIME</td>
    <td class="tg-0lax">Jack Armitage</td>
  </tr>
  <tr>
    <td class="tg-cly1">12:25</td>
    <td class="tg-cly1">Embedded AI: Some unconventional considerations for the NIME space</td>
    <td class="tg-cly1">Rebecca Fiebrink</td>
  </tr>
  <tr>
    <td class="tg-cly1">12:45</td>
    <td class="tg-cly1">Classification and Neural Audio Synthesis on a Raspberry Pi: a Practice-based-Research Enquiry</td>
    <td class="tg-cly1">Mark Hanslip</td>
  </tr>
  <tr>
    <td class="tg-cly1">13:00</td>
    <td class="tg-cly1">The Neuralacoustics Project: Exploring Deep-Learning for Lightweight Numerical Modeling Synthesis</td>
    <td class="tg-cly1">Victor Zappi and Kıvanç Tatar</td>
  </tr>
  <tr>
    <td class="tg-cly1">13:15</td>
    <td class="tg-cly1">Embedded Real-Time Expressive Guitar Technique Recognition</td>
    <td class="tg-cly1">Domenico Stefani</td>
  </tr>
  <tr>
    <td class="tg-cly1"><b>13:30</b></td>
    <td class="tg-yla0"><b>Break</b></td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-cly1">13:45</td>
    <td class="tg-cly1">DDSP Here, There and Everywhere</td>
    <td class="tg-0lax">Lamtharn "Hanoi" Hantrakul</td>
  </tr>
  <tr>
    <td class="tg-cly1">14:00</td>
    <td class="tg-cly1">Embedding Embodied Music Generation</td>
    <td class="tg-cly1">Charles Martin</td>
  </tr>
  <tr>
    <td class="tg-cly1">14:15</td>
    <td class="tg-cly1">Discussion</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-cly1">14:55</td>
    <td class="tg-cly1">Closing</td>
    <td class="tg-0lax"></td>
  </tr>
</tbody>
</table>

<h4 class="header-light regular-pad">Session 2 (19:00 - 22:00)</h4>

<table id="customers">
<thead>
  <tr>
    <th width="18%">Start</th>
    <th class="tg-1wig">Activity</th>
    <th width="28%">Speakers</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-cly1">19:00</td>
    <td class="tg-cly1">Welcome and introduction</td>
    <td class="tg-1wig"></td>
  </tr>
  <tr>
    <td class="tg-cly1">19:05</td>
    <td class="tg-cly1">Considering Ethics, Culture and Invention in Embedded AI Research for NIME</span></td>
    <td class="tg-0lax">Jack Armitage</td>
  </tr>
  <tr>
    <td class="tg-cly1">19:25</td>
    <td class="tg-cly1">Embedded AI: Some unconventional considerations for the NIME space</td>
    <td class="tg-cly1">Rebecca Fiebrink</td>
  </tr>
  <tr>
    <td class="tg-cly1">19:45</td>
    <td class="tg-cly1">Bela AI Toolbench</td>
    <td class="tg-cly1">Ezra Pierce</td>
  </tr>
  <tr>
    <td class="tg-cly1">20:00</td>
    <td class="tg-cly1">Deep Learning for Bela</td>
    <td class="tg-cly1">Rodrigo Diaz</td>
  </tr>
  <tr>
    <td class="tg-cly1">20:15</td>
    <td class="tg-cly1">Tensil.ai</td>
    <td class="tg-cly1">Tom Alcorn</td>
  </tr>
  <tr>
    <td class="tg-cly1"><b>20:30</b></td>
    <td class="tg-cly1"><b>Break</b></td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-cly1">20:45</td>
    <td class="tg-cly1">Real-time DNN-based analysis at audio rate</td>
    <td class="tg-cly1">Andrea Martelloni</td>
  </tr>
  <tr>
    <td class="tg-cly1">21:00</td>
    <td class="tg-cly1">Real-time FM tone transfer with Bela</td>
    <td class="tg-cly1">Franco Caspe</td>
  </tr>
  <tr>
    <td class="tg-cly1">21:15</td>
    <td class="tg-cly1">Discussion</td>
    <td class="tg-0lax"></td>
  </tr>
  <tr>
    <td class="tg-cly1">21:55</td>
    <td class="tg-cly1">Closing</td>
    <td class="tg-0lax"></td>
  </tr>
</tbody>
</table>


</div>

<div class="container">  
<h3 class="header-light regular-pad">Get in touch :)</h3>

We use the <b>Intelligent Instruments Lab</b> <a href="https://discord.gg/fY9GYMebtJ">Discord server</a>
<br>(look for the <i>#embedded</i> channel)

<hr>
</div>